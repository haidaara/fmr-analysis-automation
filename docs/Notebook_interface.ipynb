{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92be5f09",
   "metadata": {},
   "source": [
    "# FMR Analysis automation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75e09fb",
   "metadata": {},
   "source": [
    "### 1. Configuration: \n",
    "*path:*\n",
    "- `data_folder`: location of the measured `.txt/.csv`.  \n",
    "- `results_root`: output root.  \n",
    "\n",
    "*reading:*\n",
    "- Read all `.txt/.csv` files inside `data_folder`.\n",
    "- Parse metadata from filenames  ( sample name, frequency, db value)\n",
    "\n",
    "*column setup:* \n",
    "- Validate required columns, map first column to current, and second column to dp\\dt.  \n",
    "- Normalize units (**f→GHz, I→A, H→T**).  \n",
    "- insert a new column between I and the other, and compute **\\(H = K*I + H_0\\)**.  \n",
    "\n",
    "*pre-processed files:* \n",
    "- save processed data, as .txt /csv in a results root, under same name,  \n",
    "\n",
    "\n",
    "*parameter:*\n",
    "-  Linear Relationship:\\( H = K*I + H_0 \\) with `k = 64.4`, `H_0 = 7.914`.    \n",
    "- for debugging cause giving the needed `f` frequency to work on is handfull.\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "> Tip: we'll see if we could load a configure `config.json`\\ or `.yaml` as default configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acacaee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_setup(results_root, sample , f , db ); \n",
    "# it's single spectrum loading function, \n",
    "    # results_root: the folder that contain all data files,  # noting: load processed files.\n",
    "    # sample: sample name, so it can path to subfolder inside results_root,\n",
    "    # f: frequency,\n",
    "    # db: decibel value.\n",
    "# a default value could be set : path, sample, f = 3 (GHz), db = -10 (dB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b08813",
   "metadata": {},
   "source": [
    "### 2. ploting data: \n",
    "- ploting signal vs H, \n",
    "    ( the plot is just for visualization of raw data, before any fitting model )\n",
    "    ( to make sure plot between column B and C ( i.e. H and dH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf2ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrum(sample, f, db); # the plotting function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b80ca90",
   "metadata": {},
   "source": [
    "### 2. Single spectrum fits \n",
    "- a general function that take needed fitting function as parameter\n",
    "- define fitting model: \n",
    "    - By lorentzain\n",
    "    - By double lorentzian\n",
    "    - or other needed to be defined\n",
    "- the fit should be done on the plotted data, i.e. processed file in results\n",
    "- Auto-initial guess with peak detection\n",
    "- Fit with baseline correction\n",
    "- Output per file: ( may be of csv, or txt), \n",
    "    - Output per file: H_res, ΔH_pp, ΔH_½, amplitude, fit_quality, uncertainties\n",
    "    - Quality flags: SNR, residual analysis, single peak validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0adec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_spectrum(results_root, fitting_model); # the fitting function\n",
    "                                            # we will create an alias for different fitting model\n",
    "                                            # fitting_model: lorentzian, double_lorentzian, asymmetric_lorentzian, ...\n",
    "                                            # as always defaults parameter are registered based on parsed data in file names, but they could be changed in user request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5b454d",
   "metadata": {},
   "source": [
    "### 3. automation process \n",
    "- Iterate through all files automatically, \n",
    "    - by same procedure as above\n",
    "- output of fitting process over all files is one table with one line for each file, each output value should have it's column, \n",
    "- with saved plots. \n",
    "\n",
    "### 4. merging plots.\n",
    "- for each processed data, the plots will be saved a with header (title)  sample name, frequency.\n",
    "- at the end the plots will be merged into pptx document each in one slide. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc7ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "automation_analysis(results_root, fitting_model);\n",
    "# the main script to call all functions above \n",
    "# this will be a function that will loop over all data files in the results_root folder\n",
    "# and call the loading, plotting, and fitting functions automatically\n",
    "# parameters could be set as default or user defined,\n",
    "# ouptput per sample: named: sample_name_analysis.xlsx in excel file format, \n",
    "# excel file contain exactly in this order: f (GHz), H_res , error( on H_res), Delta_H, error (on Delta_H), R2, Adj_R2, RMSE, SSE, MSE, fitting_model\n",
    "\n",
    "# function will be created as modules in a package, so no need to define main function here, or write it's script here.\n",
    "# here we just define the function calls and their parameters.\n",
    "\n",
    "merge_plots_to_pptx(results_root, pptx_name);\n",
    "# this function will merge all saved plots into one pptx file,\n",
    "# pptx_name: sample_name_frequency.pptx\n",
    "# results_root: the folder that contain all data files,  # noting: load processed files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d7ca9",
   "metadata": {},
   "source": [
    "### 5. Batch Kittel Fitting\n",
    "- Kittel analysis consist of plotting  frequency in terms of H_res + error \n",
    "- Fitting to kittel ( a defined fonction) `f = γ/2π * √{H(H + M)} `\n",
    "- -> extract from fitting: `γ/2π` and `M_eff` with confidence intervals \n",
    "- output per sample: name:  damping_analysis.xlsx , with fitting parameter \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96db76f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kittel_fitting(results_root, kittel_output_name);\n",
    "# we may create a function that will do the kittel fitting automatically for all samples\n",
    "# or use the same fit_spectrum function with a different fitting model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7915ea",
   "metadata": {},
   "source": [
    "### 6. Batch Damping Extraction\n",
    "from the same excell file; \n",
    "- plot `ΔH vs f` \n",
    "    - fitting model here is: $ ΔH = \\frac{2α}{\\gamma} f + ΔH_0 $\n",
    "    - fitted parmater: slope $ \\frac{2α}{γ} $ and y-intercept: `\\Delta{H_0}` should be saved into same file damping_analysis, \n",
    "\n",
    "- damping is then calculated from slope: ` α = γ\\2 * slope `\n",
    "- Output per sample: α, ΔH₀ with confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e2cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "damping_fitting(results_root, damping_output_name);\n",
    "# we may create a function that will do the kittel fitting automatically for all samples\n",
    "# or use the same fit_spectrum function with a different fitting model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d8343",
   "metadata": {},
   "source": [
    "### 7. Quality assurance dashboard \n",
    "**What to check:**\n",
    "- needed results to check and log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb24d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouptput repo should contain: \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d52733",
   "metadata": {},
   "source": [
    "### 8. Results Export & Reporting\n",
    "- results table: all samples with parameters and uncertainties\n",
    "- Exporting figures in PNG/SVG format\n",
    "- CSV/Excel export of all analysis results\n",
    "- Summary report with QA status and key findings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de3ba5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cc3fcf2",
   "metadata": {},
   "source": [
    "### 9. One‑click pipeline (default settings)\n",
    "Runs the full chain with sensible defaults. Use this when you don’t need to tweak anything.\n",
    "\n",
    "**Run (one call):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b27f454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821dd08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
