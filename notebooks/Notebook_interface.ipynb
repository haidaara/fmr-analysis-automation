{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92be5f09",
   "metadata": {},
   "source": [
    "# FMR Analysis automation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75e09fb",
   "metadata": {},
   "source": [
    "### 1. Configuration: \n",
    "*path:*\n",
    "- `data_folder`: location of the measured `.txt/.csv`.  \n",
    "- `results_root`: output root.  \n",
    "\n",
    "*reading:*\n",
    "- Read all `.txt/.csv` files inside `data_folder`.\n",
    "- Parse metadata from filenames  ( sample name, frequency, db value)\n",
    "- AZ5_f5GHz_m20dB_1.txt, AZ5_f5GHz_m20dB_2.csv files name are like that\n",
    "\n",
    "*column setup:* \n",
    "- Validate required columns, map first column to current, and second column to dp\\dH.  \n",
    "- Normalize units (**f→GHz, I→A, H→T**).  \n",
    "- insert a new column between I and the other, and compute **\\(H = K*I + H_0\\)**.  \n",
    "\n",
    "*pre-processed files:* \n",
    "- save processed data, as .txt /csv in a results root, under same name,  \n",
    "\n",
    "\n",
    "*parameter:*\n",
    "-  Linear Relationship:\\( H = K*I + H_0 \\) with `k = 64.404`, `H_0 = 7.918`.    \n",
    "- for debugging cause giving the needed `f` frequency to work on is handfull.\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "> Tip: we'll see if we could load a configure `config.json`\\ or `.yaml` as default configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acacaee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading_setup(data_path, results_root, sample , f , db ); \n",
    "# it's single spectrum loading function, \n",
    "    # data_path = path to the data file,\n",
    "    # results_root: root path to results folder,\n",
    "    # sample: sample name, so it can path to subfolder inside results_root,\n",
    "    # f: frequency,\n",
    "    # db: decibel value.\n",
    "# a default value could be set : path, sample, f = 3 (GHz), db = -10 (dB)\n",
    "# AZ5_f5GHz_m20dB_1.txt, AZ5_f5GHz_m20dB_2.csv files name are like that\n",
    "# head data/AZ5_f5GHz_m20dB_1.txt example: \n",
    "# 1.500000        ,       -0.009819\n",
    "#         1.500000        ,       -0.026088\n",
    "#         1.500000        ,       -0.024799\n",
    "#         1.500000        ,       -0.072158\n",
    "#         1.500000        ,       -0.062976\n",
    "#         1.498000        ,       -0.096964\n",
    "#         1.498000        ,       -0.045257\n",
    "#         1.498000        ,       -0.034786\n",
    "#         1.498000        ,       -0.099220\n",
    "#         1.496000        ,       -0.204085\n",
    "# head data/AZ5_f5GHz_m20dB_2.csv example:\n",
    "# \"1.500000\t\",#VALUE!,\"\t-0.029310\t\"\n",
    "# \"\t1.500000\t\",,\"\t-0.084078\t\"\n",
    "# \"\t1.500000\t\",,\"\t-0.108885\t\"\n",
    "# \"\t1.500000\t\",,\"\t-0.089232\t\"\n",
    "# \"\t1.500000\t\",,\"\t-0.062493\t\"\n",
    "# \"\t1.498000\t\",,\"\t-0.059754\t\"\n",
    "# \"\t1.498000\t\",,\"\t-0.094065\t\"\n",
    "# \"\t1.498000\t\",,\"\t-0.049767\t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b7580c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.10' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/msys64/ucrt64/bin/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.path.append('../scripts')  # from notebooks/ directory, go up one level to scripts\n",
    "\n",
    "# from notebook_utils_Version2 import loading_setup\n",
    "\n",
    "# data_path = \"../data/AZ5_f5GHz_m20dB_1.txt\"\n",
    "# results_root = \"../results_roots\"\n",
    "# sample = \"AZ5\"\n",
    "# f = 5\n",
    "# db = -20\n",
    "\n",
    "# loading_setup(data_path, results_root, sample, f, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b08813",
   "metadata": {},
   "source": [
    "### 2. ploting data: \n",
    "- ploting signal vs H, \n",
    "    ( the plot is just for visualization of raw data, before any fitting model )\n",
    "    ( to make sure plot between column B and C ( i.e. H and dP/dH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf2ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_spectrum(sample, f, db); # the plotting function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b80ca90",
   "metadata": {},
   "source": [
    "### 2. Single spectrum fits \n",
    "- a general function that take needed fitting function as parameter\n",
    "- define fitting model: \n",
    "    - By lorentzain\n",
    "    - By double lorentzian\n",
    "    - or other needed to be defined\n",
    "- the fit should be done on the plotted data, i.e. processed file in results\n",
    "- Auto-initial guess with peak detection\n",
    "- Fit with baseline correction\n",
    "- Output per file: ( may be of csv, or txt), \n",
    "    - Output per file: H_res, ΔH_pp, ΔH_½, amplitude, fit_quality, uncertainties\n",
    "    - Quality flags: SNR, residual analysis, single peak validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0adec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_spectrum(results_root, fitting_model); # the fitting function\n",
    "                                            # we will create an alias for different fitting model\n",
    "                                            # fitting_model: lorentzian, double_lorentzian, asymmetric_lorentzian, ...\n",
    "                                            # as always defaults parameter are registered based on parsed data in file names, but they could be changed in user request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5b454d",
   "metadata": {},
   "source": [
    "### 3. automation process \n",
    "- Iterate through all files automatically, \n",
    "    - by same procedure as above\n",
    "- output of fitting process over all files is one table with one line for each file, each output value should have it's column, \n",
    "- with saved plots. \n",
    "\n",
    "### 4. merging plots.\n",
    "- for each processed data, the plots will be saved a with header (title)  sample name, frequency.\n",
    "- at the end the plots will be merged into pptx document each in one slide. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc7ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automation_analysis(results_root, fitting_model);\n",
    "# # the main script to call all functions above \n",
    "# # this will be a function that will loop over all data files in the results_root folder\n",
    "# # and call the loading, plotting, and fitting functions automatically\n",
    "# # parameters could be set as default or user defined,\n",
    "# # ouptput per sample: named: sample_name_analysis.xlsx in excel file format, \n",
    "# # excel file contain exactly in this order: f (GHz), H_res , error( on H_res), Delta_H, error (on Delta_H), R2, Adj_R2, RMSE, SSE, MSE, fitting_model\n",
    "\n",
    "# # function will be created as modules in a package, so no need to define main function here, or write it's script here.\n",
    "# # here we just define the function calls and their parameters.\n",
    "\n",
    "# merge_plots_to_pptx(results_root, pptx_name);\n",
    "# # this function will merge all saved plots into one pptx file,\n",
    "# # pptx_name: sample_name_frequency.pptx\n",
    "# # results_root: the folder that contain all data files,  # noting: load processed files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d7ca9",
   "metadata": {},
   "source": [
    "### 5. Batch Kittel Fitting\n",
    "- Kittel analysis consist of plotting  frequency in terms of H_res + error \n",
    "- Fitting to kittel ( a defined fonction) `f = γ/2π * √{H(H + M)} `\n",
    "- -> extract from fitting: `γ/2π` and `M_eff` with confidence intervals \n",
    "- output per sample: name:  damping_analysis.xlsx , with fitting parameter \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96db76f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kittel_fitting(results_root, kittel_output_name);\n",
    "# we may create a function that will do the kittel fitting automatically for all samples\n",
    "# or use the same fit_spectrum function with a different fitting model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7915ea",
   "metadata": {},
   "source": [
    "### 6. Batch Damping Extraction\n",
    "from the same excell file; \n",
    "- plot `ΔH vs f` \n",
    "    - fitting model here is: $ ΔH = \\frac{2α}{\\gamma} f + ΔH_0 $\n",
    "    - fitted parmater: slope $ \\frac{2α}{γ} $ and y-intercept: `\\Delta{H_0}` should be saved into same file damping_analysis, \n",
    "\n",
    "- damping is then calculated from slope: ` α = γ\\2 * slope `\n",
    "- Output per sample: α, ΔH₀ with confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e2cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# damping_fitting(results_root, damping_output_name);\n",
    "# we may create a function that will do the kittel fitting automatically for all samples\n",
    "# or use the same fit_spectrum function with a different fitting model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d8343",
   "metadata": {},
   "source": [
    "### 7. Quality assurance dashboard \n",
    "**What to check:**\n",
    "- needed results to check and log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb24d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouptput repo should contain: \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d52733",
   "metadata": {},
   "source": [
    "### 8. Results Export & Reporting\n",
    "- results table: all samples with parameters and uncertainties\n",
    "- Exporting figures in PNG/SVG format\n",
    "- CSV/Excel export of all analysis results\n",
    "- Summary report with QA status and key findings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de3ba5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cc3fcf2",
   "metadata": {},
   "source": [
    "### 9. One‑click pipeline (default settings)\n",
    "Runs the full chain with sensible defaults. Use this when you don’t need to tweak anything.\n",
    "\n",
    "**Run (one call):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b27f454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821dd08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
